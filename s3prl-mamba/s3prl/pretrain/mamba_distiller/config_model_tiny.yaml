distiller:
  # Extractor
  extractor_mode: default
  extractor_conv_feature_layers: '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2'
  extractor_dropout: 0.0
  feature_grad_mult: 0.1

  # Convolutional relative positional encoding
  conv_pos: 128
  conv_pos_groups: 16

  # Mamba encoder config
  encoder_arch: tiny
  direction: uni
  mamba_type: mamba
  ffn_dim: 0
  activation_fn: relu
  dropout: 0.1
  activation_dropout: 0.1
  ssm_cfg:
    d_state: 24
    d_conv: 4
    expand: 3
  residual_in_fp32: True 

  # Output
  final_dim: 768
  out_layer_type: expand-last

  # Task & loss
  n_tasks: 3
  task_emb_type: expand-last
  loss_type: l1
  feat_pen_loss: 0.0
  cosine_loss: 1.0  # cosine similarity loss
  pred_layer_id: [4, 8, 12]

  # Initialization
  init_teacher_conv_layers: true

teacher:
  model: hubert_base
  n_layers: 12

task:
  sequence_length: 250000  # 15.6 secs

audio:
  target_level: None
